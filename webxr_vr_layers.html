<!DOCTYPE html>
<html lang="en">

<head>
	<title>three.js vr - layers</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
</head>

<body>

	<div id="info">
		<a href="https://threejs.org" target="_blank" rel="noopener">three.js</a> media and projection layers<br />
		(Oculus Browser 16.1+)

		<p> This example demonstrates the use of <a href="https://www.w3.org/TR/webxrlayers-1/">WebXR Layers</a> to
			render high quality text and video.
			For static content such as text, using layers increases the usable resolution of the content by avoiding the
			extra resampling pass that occurs during normal VR rendering.
			For dynamic content such as video, using layers also improves performance by only copying data when new
			frames are available. </p>
		<br />
		<p><i>See the comments in the code for more information.</i></p>

	</div>
	<script src="webxr-layers-polyfill.js">
		let layersPolyfill = new WebXRLayersPolyfill()
	</script>
  <script src="./encoder/build/basis_loader.js"></script>

	<script type="importmap">
			{
			  "imports": {
				"three": "https://cdn.jsdelivr.net/npm/three@0.166.1/build/three.module.js",
				"three/addons/": "https://cdn.jsdelivr.net/npm/three@0.166.1/examples/jsm/"
			  }
			}
		  </script>



	<script defer type="module">
		import * as THREE from 'three';
		import { GUI } from 'three/addons/libs/lil-gui.module.min.js';
		import { HTMLMesh } from 'three/addons/interactive/HTMLMesh.js';
		import { InteractiveGroup } from 'three/addons/interactive/InteractiveGroup.js';
		import { VRButton } from 'three/addons/webxr/VRButton.js';
		import { XRControllerModelFactory } from 'three/addons/webxr/XRControllerModelFactory.js';
		import { XRHandModelFactory } from 'three/addons/webxr/XRHandModelFactory.js';
		import { KTX2Loader } from 'three/addons/loaders/KTX2Loader.js';


		let camera, scene, renderer;
		let video;

		// Four eye charts are rendered to demonstrate the differences in text quality.
		// The two charts on the top are rendered into XRQuadLayers ( substantially more legible ).
		// The two charts on the bottom are rendered to the eye buffer.
		//
		// The two charts on the left are rendered without mipmaps and have aliasing artifacts.
		// The two charts on the right are with mipmaps an don't twinkle but are blurrier.
		// To maximize text legibility, it's important to choose a texture size optimized for the
		// distance of the text. (This example intentionally uses incorrectly large textures to
		// demonstrate this issue.) If the optimal text size can't be determined beforehand, then
		// mipmaps are required to avoid aliasing.
		//
		// The background of the scene is an equirectangular layer. It uses an XRMediaBinding to
		// render the contents of a video element into the scene. This example uses a low resolution
		// video to avoid large files, but using media layers allows video that is higher resolution than normal rendering.

		let snellenTexture;
		let quadLayerPlain;
		let quadLayerMips;
		let guiLayer;
		let guiMesh;
		let errorMesh;
		let equirectLayer;
		let imgsrc = 'textures/castle2.jpg'
		let projLayer = null;
		let eqrtImageElement = null;
		let eqrtIsStereo = false;
		let eqrtIs180 = false;
		let eqrtTextureWidth = 0;
		let eqrtTextureHeight = 0;
		let eqrtRadius = 40;
		let glBinding;
		let mediaBinding;
		let xrSpace;
		let NEW_PATH = "textures/equirectangular.png"
		let xrSession = null;
		let ktx2Textures = []
		let img3;
		let gl;
		let testQuad = null;
		let ext;

		// Set via GUI.
		const parameters = {
			eyeChartDistanceFt: 20,
		};

		// Data shared between the THREE.Meshes on the bottom and WebXR Layers on the top for the eye
		// charts. See https://en.wikipedia.org/wiki/Snellen_chart for details about the math.
		//
		// The image was designed so that each 2x2px block on the 20/20 line subtends 1 minute of
		// arc. That is
		//    tan(1/60 deg) * 6.1m * 160px/142mm = 2px
		// per block on line 8.
		//
		// This fidelity is beyond any modern consumer headset since it would require ~60px/deg of
		// resolution. The Quest has ~16ppd and the Quest 2 has ~20ppd so only lines 3 or 4 will be
		// legible when using layers. Without layers, you lose ~sqrt(2) in resolution due to the
		// extra resampling.
		const snellenConfig = {
			// The texture is a power of two so that mipmaps can be generated.
			textureSizePx: 512,
			// This is the valid part of the image.
			widthPx: 320,
			heightPx: 450,

			x: 0,
			y: 1.5,
			z: - 6.1, // 20/20 vision @ 20ft = 6.1m

			// This is the size of mesh and the visible part of the quad layer.
			widthMeters: .268, // 320px image * (142mm/160px scale factor)
			heightMeters: .382 // 450px image * (142mm/160px scale factor)
		};

		snellenConfig.cropX = snellenConfig.widthPx / snellenConfig.textureSizePx;
		snellenConfig.cropY = snellenConfig.heightPx / snellenConfig.textureSizePx;

		// The quad layer is a [-1, 1] quad but only a part of it has image data. Scale the layer so
		// that the part with image data is the same size as the mesh.
		snellenConfig.quadWidth = .5 * snellenConfig.widthMeters / snellenConfig.cropX;
		snellenConfig.quadHeight = .5 * snellenConfig.heightMeters / snellenConfig.cropY;

		init();

		function init() {

			scene = new THREE.Scene();

			camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 10);
			camera.position.set(0, 1.6, 3);

			const hemLight = new THREE.HemisphereLight(0x808080, 0x606060, 3);
			const light = new THREE.DirectionalLight(0xffffff, 3);
			scene.add(hemLight, light);
			window.texs = ktx2Textures
			//

			renderer = new THREE.WebGLRenderer({ antialias: false });
			window.renderer = renderer
			renderer.setPixelRatio(window.devicePixelRatio);
			renderer.setSize(window.innerWidth, window.innerHeight);
			renderer.setAnimationLoop(animate);
			renderer.setClearAlpha(1);
			renderer.setClearColor(new THREE.Color(0), 0);
			renderer.xr.enabled = true;

			document.body.appendChild(renderer.domElement);
			document.body.appendChild(VRButton.createButton(renderer));

			// rando object test...?




			let imageDataUrl;
			// ktx2
			var ktx2Loader = new KTX2Loader();
			ktx2Loader.setTranscoderPath('https://cdn.jsdelivr.net/npm/three@0.154.0/examples/jsm/libs/basis/');
			ktx2Loader.detectSupport(renderer);
			//ktx parse
			ktx2Loader.load('textures/snowyPark.ktx2',//
				(texture) => {
					console.log(texture);
					ktx2Textures.push(texture)
					const material = new THREE.MeshBasicMaterial({ map: texture });
					const geometry = new THREE.BoxGeometry(1, 1, 1);

					const cube = new THREE.Mesh(geometry, material);
					scene.add(cube);

					// const geometry = new THREE.PlaneGeometry(4, 4);
					// const mesh = new THREE.Mesh(geometry, material);
					// scene.add(mesh);
					// imageDataUrl = renderer.domElement.toDataURL();
					// img3 = document.createElement('img');
					// img3.src = imageDataUrl;
					// img3.onload = () => {
					// 	document.body.appendChild(img3);
					// 	console.log("here?")
					// }

					// Append the image element to the document body

					// material.side = THREE.BackSide
					// materials[i] = material
					// tex = texture
					//   var material = new THREE.MeshStandardMaterial( { map: texture } );
					//   texture.encoding = THREE.sRGBEncoding;
					//   material.map = texture;
					//   material.needsUpdate = true;
					//   // swap(material)
					// }, undefined, (error) => {
					//   console.error(error);
				}
			);

			// controllers



			const lineGeometry = new THREE.BufferGeometry().setFromPoints([
				new THREE.Vector3(0, 0, 0),
				new THREE.Vector3(0, 0, - 10)
			]);
			const line = new THREE.Line(lineGeometry, new THREE.LineBasicMaterial({ color: 0x5555ff }));

			// The invisible dummyMesh quads and the guiMesh need to be rendered before the controller lines so that they
			// leave a hole in the depth buffer that the lines can intersect.
			line.renderOrder = 1;

			const controllerModelFactory = new XRControllerModelFactory();
			const handModelFactory = new XRHandModelFactory().setPath('./models/fbx/');

			//

			const controllers = [
				renderer.xr.getController(0),
				renderer.xr.getController(1)
			];

			controllers.forEach((controller, i) => {

				const controllerGrip = renderer.xr.getControllerGrip(i);
				controllerGrip.add(controllerModelFactory.createControllerModel(controllerGrip));
				scene.add(controllerGrip);

				const hand = renderer.xr.getHand(i);
				hand.add(handModelFactory.createHandModel(hand));

				controller.add(line.clone());
				scene.add(controller, controllerGrip, hand);

			});

			// Eye charts

			const eyeCharts = new THREE.Group();
			eyeCharts.position.z = snellenConfig.z;
			scene.add(eyeCharts);

			snellenTexture = new THREE.TextureLoader().load('textures/snellen.png');
			snellenTexture.repeat.x = snellenConfig.cropX;
			snellenTexture.repeat.y = snellenConfig.cropY;
			snellenTexture.generateMipmaps = false;
			snellenTexture.minFilter = THREE.LinearFilter;
			const snellenMeshPlain = new THREE.Mesh(
				new THREE.PlaneGeometry(snellenConfig.widthMeters, snellenConfig.heightMeters),
				new THREE.MeshBasicMaterial({ map: snellenTexture }));
			snellenMeshPlain.position.x = snellenConfig.x - snellenConfig.widthMeters;
			snellenMeshPlain.position.y = snellenConfig.y - snellenConfig.heightMeters;
			eyeCharts.add(snellenMeshPlain);

			snellenTexture = new THREE.TextureLoader().load('textures/snellen.png');
			snellenTexture.repeat.x = snellenConfig.cropX;
			snellenTexture.repeat.y = snellenConfig.cropY;
			const snellenMeshMipMap = new THREE.Mesh(
				new THREE.PlaneGeometry(snellenConfig.widthMeters, snellenConfig.heightMeters),
				new THREE.MeshBasicMaterial({ map: snellenTexture }));
			snellenMeshMipMap.position.x = snellenConfig.x + snellenConfig.widthMeters;
			snellenMeshMipMap.position.y = snellenConfig.y - snellenConfig.heightMeters;
			eyeCharts.add(snellenMeshMipMap);

			// The layers don't participate depth testing between each other. Since the projection
			// layer is rendered last, any 3D object will incorrecly overlap layers. To avoid this,
			// invisible quads can be placed into the scene to participate in depth testing when the
			// projection layer is rendered.
			const dummyMeshLeft = new THREE.Mesh(
				new THREE.PlaneGeometry(snellenConfig.widthMeters, snellenConfig.heightMeters),
				new THREE.MeshBasicMaterial({ colorWrite: false }));
			dummyMeshLeft.position.x = snellenConfig.x - snellenConfig.widthMeters;
			dummyMeshLeft.position.y = snellenConfig.y + snellenConfig.heightMeters;
			eyeCharts.add(dummyMeshLeft);

			const dummyMeshRight = dummyMeshLeft.clone(true);
			dummyMeshRight.position.x = snellenConfig.x + snellenConfig.widthMeters;
			eyeCharts.add(dummyMeshRight);

			// The GUI is rendered into an invisible HTMLMesh and the backing canvas's data is copied
			// into a layer as required. Hit testing and interaction is done using standard HTMLMesh
			// behavior, but since the layer is in the same place as the invisible mesh, the user
			// thinks they're directly interacting with the layer.
			const gui = new GUI({ width: 300 });
			gui.add(parameters, 'eyeChartDistanceFt', 1.0, 20.0).onChange(onChange);
			gui.domElement.style.visibility = 'hidden';

			function onChange() {

				eyeCharts.position.z = - parameters.eyeChartDistanceFt * 0.3048;
				snellenConfig.z = eyeCharts.position.z;

				if (quadLayerPlain) {

					quadLayerPlain.transform = new XRRigidTransform({
						x: snellenConfig.x - snellenConfig.widthMeters,
						y: snellenConfig.y + snellenConfig.heightMeters,
						z: eyeCharts.position.z
					});

				}

				if (quadLayerMips) {

					quadLayerMips.transform = new XRRigidTransform({
						x: snellenConfig.x + snellenConfig.widthMeters,
						y: snellenConfig.y + snellenConfig.heightMeters,
						z: eyeCharts.position.z
					});

				}

				guiLayer.needsUpdate = true;

			}

			const group = new InteractiveGroup();
			group.listenToXRControllerEvents(controllers[0]);
			group.listenToXRControllerEvents(controllers[1]);
			scene.add(group);

			guiMesh = new HTMLMesh(gui.domElement);
			guiMesh.position.set(1.0, 1.5, - 1.0);
			guiMesh.rotation.y = - Math.PI / 4;
			guiMesh.scale.setScalar(2);
			guiMesh.material.colorWrite = false;
			guiMesh.material.transparent = false;
			group.add(guiMesh);

			// Error message if layer initialization fails.
			const errorCanvas = document.createElement('canvas');
			errorCanvas.width = 400;
			errorCanvas.height = 40;
			const errorContext = errorCanvas.getContext('2d');
			errorContext.fillStyle = '#FF0000';
			errorContext.fillRect(0, 0, errorCanvas.width, errorCanvas.height);
			errorContext.fillStyle = '#000000';
			errorContext.font = '28px sans-serif';
			errorContext.fillText('ERROR: Layers not initialized!', 10, 30);

			errorMesh = new THREE.Mesh(
				new THREE.PlaneGeometry(1, .1),
				new THREE.MeshBasicMaterial({ map: new THREE.CanvasTexture(errorCanvas) })
			);
			errorMesh.position.z = - 1;
			errorMesh.position.y = 1.5;
			errorMesh.visible = false;
			scene.add(errorMesh);

			window.addEventListener('resize', onWindowResize, false);

			video = document.createElement('video');
			video.loop = true;
			video.src = 'textures/MaryOculus.webm';



		}

		function onWindowResize() {

			camera.aspect = window.innerWidth / window.innerHeight;
			camera.updateProjectionMatrix();

			renderer.setSize(window.innerWidth, window.innerHeight);

		}
		//

		let first = true;
		function animate(t, frame) {

			const xr = renderer.xr;
			const session = xr.getSession();
			xrSession = session;
			gl = renderer.getContext();
			if(first){
				ext = gl.getExtension("WEBGL_compressed_texture_astc")
					if(ext){
						console.log("worked")
					}
					first = false;
			}


			// Init layers once in immersive mode and video is ready.
			if (session && session.renderState.layers === undefined) {

				errorMesh.visible = true;

			}

			if (
				session &&
				session.renderState.layers !== undefined &&
				session.hasMediaLayer === undefined &&
				video.readyState >= 2
			) {

				session.hasMediaLayer = true;
				session.requestReferenceSpace('local-floor').then((refSpace) => {

					// Create Quad layers for Snellen chart.
					glBinding = xr.getBinding();
					window.mediaBinding = mediaBinding;
					xrSpace = refSpace;
					let imageElement = document.createElement('img');
					imageElement.src = imgsrc;
					imageElement.onload = function () {
						eqrtTextureWidth = imageElement.width;
						eqrtTextureHeight = imageElement.height;
						eqrtImageElement = imageElement;
						equirectLayer = glBinding.createEquirectLayer({
							space: refSpace,
							viewPixelWidth: eqrtTextureWidth,
							viewPixelHeight: eqrtTextureHeight / 1,
							layout: "mono",
							colorFormat: gl.RGBA,

						});

						equirectLayer.centralHorizontalAngle = Math.PI * 2;
						equirectLayer.upperVerticalAngle = Math.PI / 2.0;
						equirectLayer.lowerVerticalAngle = -Math.PI / 2.0;
						equirectLayer.radius = eqrtRadius;
						// session.updateRenderState({ layers: [eqrtLayer] });

						console.log("loaded image")
						console.log("updating all layers?")

						session.updateRenderState({
							layers: [
								equirectLayer,
								// quadLayerPlain,
								// quadLayerMips,
								// testQuad,
								guiLayer,
								session.renderState.layers[0]
							]
						});

					}


					const quadLayerConfig = {
						width: snellenConfig.quadWidth,
						height: snellenConfig.quadHeight,
						viewPixelWidth: snellenConfig.textureSizePx,
						viewPixelHeight: snellenConfig.textureSizePx,
						isStatic: true,
						space: refSpace,
						layout: 'mono',
						transform: new XRRigidTransform({
							x: snellenConfig.x - snellenConfig.widthMeters,
							y: snellenConfig.y + snellenConfig.heightMeters,
							z: snellenConfig.z
						})
					};

					quadLayerPlain = glBinding.createQuadLayer(quadLayerConfig);

					quadLayerConfig.mipLevels = 3;
					quadLayerConfig.transform = new XRRigidTransform({
						x: snellenConfig.x + snellenConfig.widthMeters,
						y: snellenConfig.y + snellenConfig.heightMeters,
						z: snellenConfig.z
					});



					// testQuad = glBinding.createQuadLayer(
					// 	{
					// 		width: snellenConfig.quadWidth,
					// 		height: snellenConfig.quadHeight,
					// 		viewPixelWidth: snellenConfig.textureSizePx,
					// 		viewPixelHeight: snellenConfig.textureSizePx,
					// 		isStatic: false,
					// 		space: refSpace,
					// 		layout: 'mono',
					// 		transform: new XRRigidTransform({
					// 			x: snellenConfig.x - snellenConfig.widthMeters,
					// 			y: snellenConfig.y + snellenConfig.heightMeters,
					// 			z: snellenConfig.z
					// 		})
					// 	});


					quadLayerMips = glBinding.createQuadLayer(quadLayerConfig);

					// Create GUI layer.
					guiLayer = glBinding.createQuadLayer({
						width: guiMesh.geometry.parameters.width,
						height: guiMesh.geometry.parameters.height,
						viewPixelWidth: guiMesh.material.map.image.width,
						viewPixelHeight: guiMesh.material.map.image.height,
						space: refSpace,
						transform: new XRRigidTransform(guiMesh.position, guiMesh.quaternion)
					});

					// Create background EQR video layer.
					mediaBinding = new XRMediaBinding(session);
					window.glBinding = glBinding;



					// equirectLayer = mediaBinding.createEquirectLayer(image,
					// 	{
					// 		space: refSpace,
					// 		layout: 'stereo-top-bottom',
					// 		viewPixelWidth: 2048,
					// 		viewPixelHeight: 2048,
					// 	}
					// );





					errorMesh.visible = false;
					console.log("updating renderstate")

					// session.updateRenderState({
					// 	layers: [
					// 		quadLayerPlain,
					// 		quadLayerMips,
					// 		guiLayer,
					// 		session.renderState.layers[0]
					// 	]
					// });



					//video.play();

				});

			}


			if (session && equirectLayer && equirectLayer.needsRedraw) {
				console.log("what")
				let glayer = glBinding.getSubImage(equirectLayer, frame);
				//define the texture here

				// TEXTURE_CUBE_MAP expects the Y to be flipped for the faces and it already
				// is flipped in our texture image.
				gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
				gl.bindTexture(gl.TEXTURE_2D, glayer.colorTexture);
				gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, gl.RGBA, gl.UNSIGNED_BYTE, eqrtImageElement); //make this different than eqrtImageElement as a test. if this is really the only place we bind texture we can try replacing image element with the uncompressed pixel data or ktx2 texture
				gl.bindTexture(gl.TEXTURE_2D, null);
			}
			// if (equirectLayer && equirectLayer.needsRedraw) {
			// 	console.log("hmmm")
			// 	// let glayer = xrGLFactory.getSubImage(eqrtLayer, frame);
			// 	// //define the texture here

			// 	// // TEXTURE_CUBE_MAP expects the Y to be flipped for the faces and it already
			// 	// // is flipped in our texture image.
			// 	// gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
			// 	// gl.bindTexture(gl.TEXTURE_2D, glayer.colorTexture);
			// 	// gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, gl.RGBA, gl.UNSIGNED_BYTE, eqrtImageElement); //make this different than eqrtImageElement as a test. if this is really the only place we bind texture we can try replacing image element with the uncompressed pixel data or ktx2 texture
			// 	// gl.bindTexture(gl.TEXTURE_2D, null);
			// }

			if (session && testQuad && testQuad.needsRedraw) {
				console.log("drawing test quad.")

				const glayer = xr.getBinding().getSubImage(testQuad, frame);

				renderer.state.bindTexture(gl.TEXTURE_2D, glayer.vcolorTexture);

				gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);

				gl.compressedTexSubImage2D(
					gl.TEXTURE_2D,
					0,
					256,
					256,
					512,
					512,
					ext.COMPRESSED_RGBA_ASTC_4x4_KHR,
					dataBuffer //ktx2Textures[0].image,
				);

			}

			// Copy image to layers as required.
			// needsRedraw is set on creation or if the underlying GL resources of a layer are lost.
			if (session && quadLayerPlain && quadLayerPlain.needsRedraw) {
				console.log("yes.")

				const glayer = xr.getBinding().getSubImage(quadLayerPlain, frame);
				renderer.state.bindTexture(gl.TEXTURE_2D, glayer.colorTexture);
				gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);

				gl.texSubImage2D(gl.TEXTURE_2D, 0,
					(snellenConfig.textureSizePx - snellenConfig.widthPx) / 2,
					(snellenConfig.textureSizePx - snellenConfig.heightPx) / 2,
					snellenConfig.widthPx, snellenConfig.heightPx,
					gl.RGBA, gl.UNSIGNED_BYTE, dataBuffer);

			}

			// Same as above but also gl.generateMipmap.
			if (session && quadLayerMips && quadLayerMips.needsRedraw) {
				console.log("yes.")

				const glayer = xr.getBinding().getSubImage(quadLayerMips, frame);
				renderer.state.bindTexture(gl.TEXTURE_2D, glayer.colorTexture);
				gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
				gl.texSubImage2D(gl.TEXTURE_2D, 0,
					(snellenConfig.textureSizePx - snellenConfig.widthPx) / 2,
					(snellenConfig.textureSizePx - snellenConfig.heightPx) / 2,
					snellenConfig.widthPx, snellenConfig.heightPx,
					gl.RGBA, gl.UNSIGNED_BYTE, snellenTexture.image);
				gl.generateMipmap(gl.TEXTURE_2D);

			}

			// Same as above, but guiLayer.needsUpdate is set when the user interacts with the GUI.
			if (session && guiLayer && (guiLayer.needsRedraw || guiLayer.needsUpdate)) {
				console.log("yes.")

				const glayer = xr.getBinding().getSubImage(guiLayer, frame);
				renderer.state.bindTexture(gl.TEXTURE_2D, glayer.colorTexture);
				gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
				const canvas = guiMesh.material.map.image;
				gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, canvas.width, canvas.height, gl.RGBA, gl.UNSIGNED_BYTE, canvas);
				guiLayer.needsUpdate = false;

			}

			renderer.render(scene, camera);

		}


		function reloadSphere() {

			// Loading texture is async, create layer and update render state when done
			let imageElement = document.createElement('img');
			imageElement.src = NEW_PATH;
			imageElement.onload = function () {

				equirectLayer.destroy();

				eqrtTextureWidth = imageElement.width;
				eqrtTextureHeight = imageElement.height;
				eqrtImageElement = imageElement;
				equirectLayer = glBinding.createEquirectLayer({
					space: xrSpace,
					viewPixelWidth: eqrtTextureWidth,
					viewPixelHeight: eqrtTextureHeight / 1,
					layout: "mono",
				});

				equirectLayer.centralHorizontalAngle = Math.PI * 2;
				equirectLayer.upperVerticalAngle = Math.PI / 2.0;
				equirectLayer.lowerVerticalAngle = -Math.PI / 2.0;
				equirectLayer.radius = eqrtRadius;
				xrSession.updateRenderState({
					layers: [
						equirectLayer,
						quadLayerPlain,
						quadLayerMips,
						guiLayer,
						xrSession.renderState.layers[0]
					]
				});


			}


		}


		function reloadSphere2() {

			// Loading texture is async, create layer and update render state when done


			equirectLayer.destroy();

			eqrtTextureWidth = texs[0].image.width
			eqrtTextureHeight = texs[0].image.height
			// eqrtImageElement = texs[0].image;
			equirectLayer = glBinding.createEquirectLayer({
				space: xrSpace,
				viewPixelWidth: eqrtTextureWidth,
				viewPixelHeight: eqrtTextureHeight / 1,
				layout: "mono",
			});

			equirectLayer.centralHorizontalAngle = Math.PI * 2;
			equirectLayer.upperVerticalAngle = Math.PI / 2.0;
			equirectLayer.lowerVerticalAngle = -Math.PI / 2.0;
			equirectLayer.radius = eqrtRadius;
			xrSession.updateRenderState({
				layers: [
					equirectLayer,
					quadLayerPlain,
					quadLayerMips,
					guiLayer,
					xrSession.renderState.layers[0]
				]
			});




		}


		let dataBuffer;
		window.db = dataBuffer 
		async function check() {

			const ext = gl.getExtension("WEBGL_compressed_texture_astc"); // will be null if not supported

			if (ext) {
				// the file is already in the correct compressed format
				const dataArrayBuffer = await fetch(
					"./textures/snowyPark.ktx2",
				).then((response) => response.arrayBuffer())



			

			
			let dataBuffer = new Uint8Array(dataArrayBuffer);

			console.log(ArrayBuffer.isView(dataBuffer)) // false)
			console.log(dataBuffer[0]);
				// console.log("buffer array ", dataArrayBuffer)
				
				// dataBuffer = new Uint8Array(dataArrayBuffer);
		
				// console.log(dataArrayBuffer)
				// testQuad.destroy();

				
				// gl.compressedTexImage2D(
				// 	gl.TEXTURE_2D,
				// 	0, // set the base image level
				// 	ext.COMPRESSED_RGBA_S3TC_DXT1_EXT, // the compressed format we are using
				// 	512,
				// 	512, // width, height of the image
				// 	0, // border, always 0
				// 	new DataView(dataArrayBuffer),
				// );
				// gl.generateMipMap(gl.TEXTURE_2D); // create mipmap levels, like we would for a standard image
				// return texture;
			}
		}

		function update(){
			testQuad = glBinding.createQuadLayer(
					{
						width: snellenConfig.quadWidth,
						height: snellenConfig.quadHeight,
						viewPixelWidth: snellenConfig.textureSizePx,
						viewPixelHeight: snellenConfig.textureSizePx,
						isStatic: false,
						space: xrSpace,
						layout: 'mono',
						transform: new XRRigidTransform({
							x: snellenConfig.x - snellenConfig.widthMeters,
							y: snellenConfig.y + snellenConfig.heightMeters,
							z: snellenConfig.z
						})
					});
				//dataBuffer = new DataView(dataArrayBuffer).setUint8(1, 255);
				// console.log("buffer ", buffer)
				// dataBuffer = new Uint8Array(buffer)
				// console.log(dataBuffer)
				xrSession.updateRenderState({
					layers: [
						equirectLayer,
						// quadLayerPlain,
						// quadLayerMips,
						testQuad,
						// guiLayer,
						// xrSession.renderState.layers[0]
					]
				});
		}

		window.check = check
		window.reloadSphere = reloadSphere
		window.reloadSphere2 = reloadSphere2
		window.update = update

		window.go = go
		let basisLoader;

function go() {
  basisLoader = new BasisLoader();
  // console.log(gl)
  basisLoader.setWebGLContext(gl);
  load()

}

function load() {

  basisLoader.loadFromUrl('http://localhost:8080/projects/testing/ThreeJSWebXRLayers/textures/test.basis').then((result) => { //C:/xampp/htdocs/projects/webxr-samples-main/webxr-samples-main/layers-samples
	console.log(result.texture)
	  // WebGL color+alpha texture;

	// WebGL alpha texture, only if basisLoader.allowSeparateAlpha is true.
	// null if alpha is encoded in result.texture or result.alpha is false.
	result.alphaTexture;

	// True if the texture contained an alpha channel.
	result.alpha;

	// Number of mip levels in texture/alphaTexture
	result.mipLevels;

	// Dimensions of the base mip level.
	console.log(result.width);
	console.log(result.height);

	console.log(result)

	let fb = gl.createFramebuffer();

	// make this the current frame buffer
	gl.bindFramebuffer(gl.FRAMEBUFFER, fb);

	// attach the texture to the framebuffer.
	gl.framebufferTexture2D(
	  gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0,
	  gl.TEXTURE_2D, result.texture, 0);

	// check if you can read from this type of texture.
	let canRead = (gl.checkFramebufferStatus(gl.FRAMEBUFFER) == gl.FRAMEBUFFER_COMPLETE);

	// Unbind the framebuffer
	gl.bindFramebuffer(gl.FRAMEBUFFER, null);

	console.log(canRead)

  });

}




	</script>

<script>

  </script>
</body>

</html>